name: Run Python Bot

on:
  workflow_dispatch:  # Allows you to trigger manually
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours for periodic execution

jobs:
  run-bot:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6-hour timeout to prevent indefinite runs

    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Fetch full history to allow commits

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run bot script
      env:
        TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        python3 -u writeup-watcher.py || true  # Continue even if bot crashes to save files

    - name: Commit and push JSON files
      run: |
        git config --global user.name 'github-actions[bot]'
        git config --global user.email 'github-actions[bot]@users.noreply.github.com'
        git add twitter_urls.json medium_urls.json stored_urls.json
        git commit -m "Update URL storage files [bot]" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```
### Changes Made
1. **Scheduled Execution**: Added a `schedule` trigger to run the bot every 6 hours (`cron: '0 */6 * * *'`). This complements the `workflow_dispatch` for manual runs and ensures periodic execution without relying solely on manual triggers.
2. **Timeout Configuration**: Added `timeout-minutes: 360` to limit the job to 6 hours, aligning with GitHub Actions’ default job timeout to prevent unexpected termination.
3. **Full Git History**: Set `fetch-depth: 0` in the checkout step to ensure the full repository history is available for committing changes.
4. **File Commit Step**: Added a step to commit and push `twitter_urls.json`, `medium_urls.json`, and `stored_urls.json` to the repository. The `|| echo "No changes to commit"` ensures the workflow doesn’t fail if there are no changes to commit.
5. **Error Tolerance**: Added `|| true` to the `Run bot script` step to ensure the workflow proceeds to the commit step even if the bot crashes or is interrupted (e.g., via `KeyboardInterrupt`).
6. **GitHub Token**: Uses `${{ secrets.GITHUB_TOKEN }}` for authentication when pushing changes, which is automatically provided by GitHub Actions and requires repository write permissions.

### Additional Notes
- **Permissions**: Ensure your repository settings allow GitHub Actions to write to the repository. You may need to enable “Allow GitHub Actions to create and approve pull requests” in the repository’s Actions settings or use a personal access token with `repo` scope if `GITHUB_TOKEN` is insufficient.
- **File Conflict Handling**: If multiple workflow runs occur concurrently, there’s a small risk of commit conflicts when updating the JSON files. Consider adding a lock mechanism or using a database (e.g., SQLite) if this becomes an issue.
- **Timeout Adjustment**: If 6 hours is too long or short, adjust `timeout-minutes` to your needs (e.g., 60 for 1 hour). Alternatively, you could modify the Python script to exit after a certain number of cycles.
- **Requirements**: Ensure all dependencies in `requirements.txt` (e.g., `requests`, `beautifulsoup4`, `python-telegram-bot`, `colorlog`, `tqdm`, `ntscraper`) are up-to-date and compatible with Python 3.11.
- **Testing**: Test the workflow manually via `workflow_dispatch` to ensure the bot runs and commits files correctly. Check the repository for updated JSON files after each run.

### Do You Need Further Changes?
- If you want to adjust the schedule (e.g., run every 3 hours instead of 6), let me know the desired frequency.
- If you prefer a different approach for persisting files (e.g., uploading to a cloud storage service instead of committing to the repo), I can modify the workflow accordingly.
- If you want to keep the workflow as-is and not make these changes, let me know, and I’ll confirm that no updates are needed.
- If you want to re-enable the commented-out Reddit scraping code with similar file storage logic, I can include that in the Python script and update the workflow to handle `reddit_urls.json`.

Please confirm if this updated workflow meets your needs or specify any additional changes!
